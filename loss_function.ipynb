{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9MwvWUXMrXKa8PoUVACJm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apurvakumbhar/ANN/blob/main/loss_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZs1T2PWHZ_7",
        "outputId": "63efa085-379d-4d27-9c49-5ccb35386937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss = 1329709653.1871\n",
            "Epoch 100: Loss = 24929612.5917\n",
            "Epoch 200: Loss = 3197776.5655\n",
            "Epoch 300: Loss = 2743259.6163\n",
            "Epoch 400: Loss = 2667781.9771\n",
            "Epoch 500: Loss = 2603075.1676\n",
            "Epoch 600: Loss = 2542092.2313\n",
            "Epoch 700: Loss = 2484255.0228\n",
            "Epoch 800: Loss = 2429189.5327\n",
            "Epoch 900: Loss = 2376595.9999\n",
            "\n",
            "Predicted Price (approx):\n",
            "32136.4116317464\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample dataset: [rooms, area (sqft), location index]\n",
        "X = np.array([\n",
        "    [2, 1200, 0.5],\n",
        "    [3, 1500, 0.7],\n",
        "    [4, 1800, 0.9],\n",
        "    [3, 1600, 0.6],\n",
        "    [5, 2000, 1.0]\n",
        "])\n",
        "\n",
        "# Corresponding house prices (in thousands)\n",
        "Y = np.array([[25000], [30000], [40000], [32000], [50000]])\n",
        "\n",
        "# Normalize features\n",
        "X_mean = np.mean(X, axis=0)\n",
        "X_std = np.std(X, axis=0)\n",
        "X = (X - X_mean) / X_std\n",
        "\n",
        "# Normalize Y if using cross-entropy\n",
        "loss_type = 'mse'\n",
        "\n",
        "if loss_type == 'cross_entropy':\n",
        "    Y_min, Y_max = Y.min(), Y.max()\n",
        "    Y_scaled = (Y - Y_min) / (Y_max - Y_min)\n",
        "else:\n",
        "    Y_scaled = Y.copy()\n",
        "\n",
        "# Weight and bias initialization\n",
        "w = np.random.rand(3, 1)\n",
        "b = np.random.rand(1)\n",
        "lr = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "# Activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Loss functions\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    eps = 1e-15\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    z = np.dot(X, w) + b\n",
        "    # y_pred = sigmoid(z)\n",
        "\n",
        "\n",
        "    if loss_type == 'mse':\n",
        "        y_pred = z;\n",
        "        loss = mse_loss(Y_scaled, y_pred)\n",
        "        d_loss = 2 * (y_pred - Y_scaled) / len(Y)\n",
        "    elif loss_type == 'cross_entropy':\n",
        "        loss = cross_entropy_loss(Y_scaled, y_pred)\n",
        "        d_loss = (y_pred - Y_scaled) * sigmoid_derivative(y_pred)\n",
        "\n",
        "    # Gradients\n",
        "    dw = np.dot(X.T, d_loss)\n",
        "    db = np.sum(d_loss, axis=0)\n",
        "\n",
        "    # Update weights\n",
        "    w -= lr * dw\n",
        "    b -= lr * db\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
        "\n",
        "# Prediction\n",
        "new_input = np.array([[3, 1500, 0.7]])\n",
        "new_input = (new_input - X_mean) / X_std\n",
        "prediction = np.dot(new_input, w) + b\n",
        "\n",
        "\n",
        "print(\"\\nPredicted Price (approx):\")\n",
        "print(prediction[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample features: [keyword_freq, sender_score, email_length]\n",
        "X = np.array([\n",
        "    [3, 0.1, 200],  # Not spam\n",
        "    [10, 0.9, 100], # Spam\n",
        "    [1, 0.2, 150],  # Not spam\n",
        "    [7, 0.8, 120],  # Spam\n",
        "])\n",
        "\n",
        "# Labels\n",
        "Y = np.array([[0], [1], [0], [1]])\n",
        "\n",
        "# Normalize features (optional but helps with learning)\n",
        "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "W = np.random.rand(3, 1)\n",
        "b = np.random.rand(1)\n",
        "lr = 0.1\n",
        "epochs = 1000\n",
        "loss_history = []\n",
        "loss_type = 'cross-entropy'\n",
        "\n",
        "# Activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Loss functions\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    eps = 1e-15\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "# Training function\n",
        "for epoch in range(epochs):\n",
        "    z = np.dot(X, W) + b\n",
        "    y_pred = sigmoid(z)\n",
        "\n",
        "    # Select loss function\n",
        "    if loss_type == 'mse':\n",
        "        loss = mse_loss(Y, y_pred)\n",
        "        d_loss = 2 * (y_pred - Y) * sigmoid_derivative(y_pred)\n",
        "    elif loss_type == 'cross-entropy':\n",
        "        loss = cross_entropy_loss(Y, y_pred)\n",
        "        d_loss = (y_pred - Y) * sigmoid_derivative(y_pred)\n",
        "\n",
        "    # Backpropagation\n",
        "    dw = np.dot(X.T, d_loss)\n",
        "    db = np.sum(d_loss)\n",
        "\n",
        "    W -= lr * dw\n",
        "    b -= lr * db\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"[{loss_type.upper()}] Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "    loss_history.append(loss)\n",
        "\n",
        "output = sigmoid(np.dot(X, W) + b)\n",
        "print(\"\\nFinal Predictions:\")\n",
        "print(output.round())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IepVigUnHiqA",
        "outputId": "bb2a52c8-1ee0-4ebf-94a2-cf5bf1bad79f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CROSS-ENTROPY] Epoch 0, Loss: 0.3463\n",
            "[CROSS-ENTROPY] Epoch 100, Loss: 0.0858\n",
            "[CROSS-ENTROPY] Epoch 200, Loss: 0.0593\n",
            "[CROSS-ENTROPY] Epoch 300, Loss: 0.0476\n",
            "[CROSS-ENTROPY] Epoch 400, Loss: 0.0407\n",
            "[CROSS-ENTROPY] Epoch 500, Loss: 0.0360\n",
            "[CROSS-ENTROPY] Epoch 600, Loss: 0.0326\n",
            "[CROSS-ENTROPY] Epoch 700, Loss: 0.0300\n",
            "[CROSS-ENTROPY] Epoch 800, Loss: 0.0279\n",
            "[CROSS-ENTROPY] Epoch 900, Loss: 0.0262\n",
            "\n",
            "Final Predictions:\n",
            "[[0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample Data: [10th%, 12th%, CGPA, IQ]\n",
        "X = np.array([\n",
        "    [85, 80, 8.0, 110],\n",
        "    [70, 65, 6.5, 95],\n",
        "    [90, 88, 9.0, 120],\n",
        "    [60, 58, 5.8, 85],\n",
        "    [75, 70, 7.2, 100]\n",
        "])\n",
        "\n",
        "# Labels: 1 = Placed, 0 = Not Placed\n",
        "Y = np.array([[1], [0], [1], [0], [1]])\n",
        "\n",
        "# Normalize features\n",
        "X_mean = np.mean(X, axis=0)\n",
        "X_std = np.std(X, axis=0)\n",
        "X = (X - X_mean) / X_std\n",
        "\n",
        "# Initialize weights and bias\n",
        "w = np.random.rand(4, 1)\n",
        "b = np.random.rand(1)\n",
        "lr = 0.01\n",
        "epochs = 1000\n",
        "loss_type = 'cross-entropy'\n",
        "\n",
        "# Activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Loss functions\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    eps = 1e-15\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "# Training function\n",
        "for epoch in range(epochs):\n",
        "    z = np.dot(X, w) + b\n",
        "    y_pred = sigmoid(z)\n",
        "\n",
        "    # Select loss function\n",
        "    if loss_type == 'mse':\n",
        "        loss = mse_loss(Y, y_pred)\n",
        "        d_loss = 2 * (y_pred - Y) * sigmoid_derivative(y_pred)\n",
        "    elif loss_type == 'cross-entropy':\n",
        "        loss = cross_entropy_loss(Y, y_pred)\n",
        "        d_loss = (y_pred - Y) * sigmoid_derivative(y_pred)\n",
        "\n",
        "    # Backpropagation\n",
        "    dw = np.dot(X.T, d_loss)\n",
        "    db = np.sum(d_loss)\n",
        "\n",
        "    w -= lr * dw\n",
        "    b -= lr * db\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\" Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "output = sigmoid(np.dot(X, w) + b)\n",
        "print(\"\\nFinal Predictions:\")\n",
        "print(output.round())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa4xNuzxHq5u",
        "outputId": "fd1f5b0a-7297-46f0-f4e1-86434da39a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch 0, Loss: 0.1844\n",
            " Epoch 100, Loss: 0.1785\n",
            " Epoch 200, Loss: 0.1733\n",
            " Epoch 300, Loss: 0.1686\n",
            " Epoch 400, Loss: 0.1643\n",
            " Epoch 500, Loss: 0.1604\n",
            " Epoch 600, Loss: 0.1567\n",
            " Epoch 700, Loss: 0.1533\n",
            " Epoch 800, Loss: 0.1501\n",
            " Epoch 900, Loss: 0.1471\n",
            "\n",
            "Final Predictions:\n",
            "[[1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data: [Today_Temp, Humidity, WindSpeed]\n",
        "X = np.array([\n",
        "    [30, 70, 10],\n",
        "    [32, 65, 12],\n",
        "    [31, 72, 9],\n",
        "    [29, 75, 8],\n",
        "    [33, 60, 11]\n",
        "])\n",
        "\n",
        "# Target: Next day temperature\n",
        "Y = np.array([[31], [33], [32], [30], [34]])\n",
        "\n",
        "# Normalize input features\n",
        "X_mean = np.mean(X, axis=0)\n",
        "X_std = np.std(X, axis=0)\n",
        "X = (X - X_mean) / X_std\n",
        "\n",
        "loss_type = 'mse'\n",
        "\n",
        "if loss_type == 'cross_entropy':\n",
        "    Y_min, Y_max = Y.min(), Y.max()\n",
        "    Y_scaled = (Y - Y_min) / (Y_max - Y_min)\n",
        "else:\n",
        "    Y_scaled = Y.copy()\n",
        "\n",
        "# Weight and bias initialization\n",
        "w = np.random.rand(3, 1)\n",
        "b = np.random.rand(1)\n",
        "lr = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "# Activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Loss functions\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    eps = 1e-15\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    z = np.dot(X, w) + b\n",
        "    # y_pred = sigmoid(z)\n",
        "\n",
        "\n",
        "    if loss_type == 'mse':\n",
        "        y_pred = z;\n",
        "        loss = mse_loss(Y_scaled, y_pred)\n",
        "        d_loss = 2 * (y_pred - Y_scaled) / len(Y)\n",
        "    elif loss_type == 'cross_entropy':\n",
        "        loss = cross_entropy_loss(Y_scaled, y_pred)\n",
        "        d_loss = (y_pred - Y_scaled) * sigmoid_derivative(y_pred)\n",
        "\n",
        "    # Gradients\n",
        "    dw = np.dot(X.T, d_loss)\n",
        "    db = np.sum(d_loss, axis=0)\n",
        "\n",
        "    # Update weights\n",
        "    w -= lr * dw\n",
        "    b -= lr * db\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
        "\n",
        "#Predict next day temperature\n",
        "new_data = np.array([[31, 68, 10]])  # today's temp, humidity, wind speed\n",
        "new_data = (new_data - X_mean) / X_std\n",
        "prediction = np.dot(new_data, w) + b\n",
        "\n",
        "print(\"\\nForecasted Temperature (°C):\")\n",
        "print(prediction[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOePZFJaH7wG",
        "outputId": "cfc46aee-26cb-4cba-cab9-fc5563c69885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss = 971.1496\n",
            "Epoch 100: Loss = 17.2415\n",
            "Epoch 200: Loss = 0.3846\n",
            "Epoch 300: Loss = 0.0484\n",
            "Epoch 400: Loss = 0.0242\n",
            "Epoch 500: Loss = 0.0147\n",
            "Epoch 600: Loss = 0.0098\n",
            "Epoch 700: Loss = 0.0069\n",
            "Epoch 800: Loss = 0.0051\n",
            "Epoch 900: Loss = 0.0038\n",
            "\n",
            "Forecasted Temperature (°C):\n",
            "32.01206554011384\n"
          ]
        }
      ]
    }
  ]
}